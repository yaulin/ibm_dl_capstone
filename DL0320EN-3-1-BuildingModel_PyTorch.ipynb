{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/DL0320EN_TOP_IMAGE\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0320EN/Assets/Images/Top.png\" width=\"750\" alt=\"IBM 10TB Storage\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classifying European Money Denominations: Training a Pre-trained model  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this lab, you will train the pre-trained model to classify the European currency. You will use the dataset object you created in the previous lab.</p>\n",
    "<ul>\n",
    "    <li><a href=\"#gen\">Create Image Dataset Generator</a></li>\n",
    "    <li><a href=\"#ques\">Questions</a>\n",
    "        <ol>\n",
    "            <li><a href=\"q31\">Question 3.1: Preparation</a></li>\n",
    "            <li><a href=\"q32\">Question 3.2: Train the model</a></li>\n",
    "            <li><a href=\"q33\">Question 3.3: Plot 5 Random Images with their predictions</a></li>\n",
    "            <li><a href=\"q34\">Question 3.4: Use the second model <code>Densenet121</code> to do the prediction</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#save\">Save the trained model</a></li>\n",
    "</ul>\n",
    "\n",
    "<p>Estimated Time Needed: <b>60 mins</b></p>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/DL0320EN_storage\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0320EN/Assets/Images/ObjectStorage.png\" width=\"750\" alt=\"cognitive class\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the datasets you needed for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can comment out this box when you already have the dataset\n",
    "# Step 1: Ctrl + A : Select all\n",
    "# Step 2: Ctrl + / : Comment out all; if everything selected has been comment out alreaday, then uncomment all\n",
    "\n",
    "# Download Training Dataset\n",
    "!wget --quiet -O /resources/data/training_data_pytorch.tar.gz https://cocl.us/DL0320EN_TRAIN_TAR_PYTORCH\n",
    "!tar -xzf  /resources/data/training_data_pytorch.tar.gz -C /resources/data --exclude '.*'\n",
    "\n",
    "# Download Validation Dataset\n",
    "!wget --quiet -O /resources/data/validation_data_pytorch.tar.gz https://cocl.us/DL0320EN_VALID_TAR_PYTORCH\n",
    "!tar -xzf  /resources/data/validation_data_pytorch.tar.gz -C /resources/data --exclude '.*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the PyTorch Modules needed in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8044abd470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import PyTorch Modules will be used in the lab\n",
    "\n",
    "import torch \n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Non-PyTorch Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Non-PyTorch Modules will be used in the lab\n",
    "\n",
    "import time\n",
    "from imageio import imread\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"gen\">Create Dataset Class and Object</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you use the dataset class from the last section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denomination, file name and the class variable for the training and validation data are stored in the following csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url that contains CSV files\n",
    "\n",
    "train_csv_file = 'https://cocl.us/DL0320EN_TRAIN_CSV'\n",
    "validation_csv_file = 'https://cocl.us/DL0320EN_VALID_CSV'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training images and validation images  are stored in the following directories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute path for finding the directory contains image datasets\n",
    "\n",
    "train_data_dir = '/resources/data/training_data_pytorch/'\n",
    "validation_data_dir = '/resources/data/validation_data_pytorch/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use  the dataset class you created in the last lab. You can cut and paste it to here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dateaset Class\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.data_name = pd.read_csv(csv_file)\n",
    "        self.len = self.data_name.shape[0] \n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_dir + self.data_name.iloc[idx, 2]\n",
    "        image = Image.open(img_name)\n",
    "        y = self.data_name.iloc[idx, 3]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the constructor <code>compose</code> to perform the following sequence of transformations in the order they are given, call the object <code>composed</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the composed object for transforming the image\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "composed = transforms.Compose([transforms.Resize((224, 224))\n",
    "                               , transforms.ToTensor()\n",
    "                               , transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training dataset and validation dataset object using the csv file stored in the variables the <code>train_csv_file</code> and <code>validation_csv_file</code>. The directories are stored in the variable <code>train_data_dir</code> and <code>validation_data_dir</code>. Set the parameter <code>transform</code> to the object <code>composed</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train dataset and validation dataset\n",
    "\n",
    "train_dataset = Dataset(transform=composed\n",
    "                        ,csv_file=train_csv_file\n",
    "                        ,data_dir=train_data_dir)\n",
    "\n",
    "validation_dataset = Dataset(transform=composed\n",
    "                          ,csv_file=validation_csv_file\n",
    "                          ,data_dir=validation_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"ques\">Questions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"q31\">Question 3.1: Preparation</h3><b>5 points</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the pre-trained model resnet18\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "model=models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: The following lines of code will set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "\n",
    "# Type your code here\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 7 different bills. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Re-defined the last layer\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "model.fc = nn.Linear(512, 7) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model (PLEASE DO NOT MODIFY THIS BOX)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"q32\">Question 3.2: Train the model</h3><b>5 points</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "criterion= nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size is <i>15</i> and <i>10</i> respectively ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create the data loader\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "train_loader=DataLoader(train_dataset, batch_size=15)\n",
    "validation_loader=DataLoader(validation_dataset, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Use the pre-defined optimizer Adam with learning rate 0.003\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam([parameters for parameters in model.parameters() if parameters.requires_grad], lr=0.003)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 4</b>: Train the model for 20 epochs, save the loss in a list as will as the accuracy on the validation data for every epoch. The entire process may take 6.5 minutes. Print the validation accuracy for each epoch during the epoch loop. Then, plot the training loss for each epoch and validation error for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.32857142857142857\n",
      "1 0.18571428571428572\n",
      "2 0.17142857142857143\n",
      "3 0.4714285714285714\n",
      "4 0.6714285714285714\n",
      "5 0.7285714285714285\n",
      "6 0.6857142857142857\n",
      "7 0.6571428571428571\n",
      "8 0.8\n",
      "9 0.8714285714285714\n",
      "10 0.8857142857142857\n",
      "11 0.9\n",
      "12 0.9285714285714286\n",
      "13 0.9428571428571428\n",
      "14 0.9428571428571428\n",
      "15 0.9428571428571428\n",
      "16 0.9571428571428572\n",
      "17 0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the model\n",
    "\n",
    "N_EPOCHS = 20\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "correct = 0\n",
    "n_test = len(validation_dataset)\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    loss_sublist = []\n",
    "    for x,y in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x)\n",
    "        loss = criterion(z,y)\n",
    "        loss_sublist.append(loss.data.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_list.append(np.mean(loss_sublist))\n",
    "    \n",
    "    correct = 0\n",
    "    for x_test, y_test in validation_loader:\n",
    "        model.eval()\n",
    "        z = model(x_test)\n",
    "        _, yhat = torch.max(z.data, 1)\n",
    "        correct += (yhat==y_test).sum().item()\n",
    "    accuracy = correct/n_test\n",
    "    accuracy_list.append(accuracy)\n",
    "    print(epoch,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 5</b>: Plot the training loss for each iteration<br> <b>(Your peer reviewer is going to mark based on what you plot here.)</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Plot the loss for training dataset\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 6</b>: Plot the validation accuracy for each epoch<br> <b>(Your peer reviewer is going to mark based on what you plot here.)</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Plot the accuracy for valdiation dataset\n",
    "\n",
    "# Type your code here\n",
    "plt.plot(accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"q33\">Question 3.3: Plot 5 Random Images with their predictions</h3><b>5 points</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a test dataset using validation data. And, create your own <code>plot_random_image()</code> function to plot 5 random images which index is in the <code>numbers</code> list. Run the function to plot image, print the predicted label and print a string indicate whether it has been correctly classified or mis-classified.<br> <b>(Your peer reviewer is going to mark based on what you plot here.)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images with labels\n",
    "\n",
    "look_up = {0: 'predicted: $5'\n",
    "           , 1: 'predicted: $10'\n",
    "           , 2: 'predicted: $20'\n",
    "           , 3: 'predicted: $50'\n",
    "           , 4: 'predicted: $100'\n",
    "           , 5: 'predicted $200'\n",
    "           , 6: 'predicted $500'}\n",
    "random.seed(0)\n",
    "numbers = random.sample(range(70), 5)\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "\n",
    "for i in numbers:\n",
    "        img, cl = validation_dataset.__getitem__(i)\n",
    "        print(img.shape)\n",
    "        plt.imshow(img[1])\n",
    "        plt.show()\n",
    "        print(look_up[cl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question 3.4: Use the second model <code>Densenet121</code> to do the prediction</h3><b>3 points</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the steps in Question 3.1, 3.2 to predict the result using <code>models.densenet121</code> model. Then, print out the last validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Steps:</p>\n",
    "<ol>\n",
    "    <li>Load the pre-trained model Densenet</li>\n",
    "    <li>Replace the last classification layer with only 7 classes</li>\n",
    "    <li>Set the configuration (parameters)</li>\n",
    "    <li>Train the model</li>\n",
    "    <li>Print the last validation accuracy</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint:\n",
    "<ul>\n",
    "    <li>The second last layer for this model has 1024 outputs.</li>\n",
    "    <li>The last layer for <code>Densenet121</code> can be accessed by <code>model.classifier</code></li>\n",
    "    <li>Use the criterion function <code>nn.CrossEntropyLoss()</code></li>\n",
    "    <li>Train Batch Size: 15; Validation Batch Size: 10</li>\n",
    "    <li>Optimizer: Adam with learning rate 0.003</li>\n",
    "    <li>10 Epoches. Otherwise, it will take too long.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are welcome to try any pattern of setting and find out the best result. Please name the model variable as <code>model_des</code>.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use densenet121 to train the model and print out the last validation accuracy.\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "model_des=models.Densenet121(pretrained=True)\n",
    "\n",
    "for param in model_des.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model_des.classifier=nn.Linear(1024, 7)\n",
    "\n",
    "criterion= nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "N_EPOCHS = 20\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "correct = 0\n",
    "n_test = len(validation_dataset)\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    loss_sublist = []\n",
    "    for x,y in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x)\n",
    "        loss = criterion(z,y)\n",
    "        loss_sublist.append(loss.data.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_list.append(np.mean(loss_sublist))\n",
    "    \n",
    "    correct = 0\n",
    "    for x_test, y_test in validation_loader:\n",
    "        model.eval()\n",
    "        z = model(x_test)\n",
    "        _, yhat = torch.max(z.data, 1)\n",
    "        correct += (yhat==y_test).sum().item()\n",
    "    accuracy = correct/n_test\n",
    "    accuracy_list.append(accuracy)\n",
    "    print(epoch,accuracy)\n",
    "\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.plot(accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"#save\">Save the trained model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model for the following chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "torch.save(model, \"resnet18_pytorch.pt\")\n",
    "torch.save(model_des, \"densenet121_pytorch.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/DLO0320EN_notebook_bott\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0320EN/Assets/Images/Bottom.png\" width=\"750\" alt=\"cognitive class\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>, <a href=\"https://www.linkedin.com/in/yi-leng-yao-84451275/\">Yi Leng Yao</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
